{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get\n",
    "\n",
    "import itertools\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model, svm, tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from  sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "#import swifter\n",
    "\n",
    "np.random.seed(1907)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# from tqdm.auto import tqdm  # for notebooks\n",
    "\n",
    "#tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_data_preparation():\n",
    "    try:\n",
    "        data = pd.read_csv(\"survey_results_public.csv\")\n",
    "        print(\"Data loaded locally.\")\n",
    "    except:\n",
    "        data = pd.read_csv(r\"https://raw.githubusercontent.com/ahmetsirel/ozu_data_science/master/DS%20555%20-%20Data%20Science%20%26%20Strategy/Project/survey_results_public.csv\")\n",
    "        print(\"Data loaded from github.\")\n",
    "    \n",
    "    \n",
    "    print(f\"{len(data)} Rows.\")\n",
    "\n",
    "    # Numeric columns\n",
    "    data[\"Age1stCode\"] = data[\"Age1stCode\"].replace('Younger than 5 years', \"3\").replace('Older than 85', \"90\").astype(float)\n",
    "    data[\"YearsCode\"] = data[\"YearsCode\"].replace('Less than 1 year', \"0.5\").replace('More than 50 years', \"55\").astype(float)\n",
    "    data[\"YearsCodePro\"] = data[\"YearsCodePro\"].replace('Less than 1 year', \"0.5\").replace('More than 50 years', \"55\").astype(float)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    columns_to_drop = [\"CurrencySymbol\", \"CompFreq\", \"CurrencyDesc\", \"CompTotal\", \"Respondent\"]\n",
    "    data = data.drop(columns_to_drop, axis=1)\n",
    "\n",
    "    # Process multi choise columns\n",
    "    def get_all_distinct_choices(column_name):\n",
    "        list_of_choices = [str(item).split(\";\") for item in data[column_name].unique()]\n",
    "        all_choices = []\n",
    "        for ch in list_of_choices:\n",
    "            all_choices += ch\n",
    "\n",
    "        all_choices.remove(\"nan\")\n",
    "        all_choices = pd.Series(all_choices).unique().tolist()\n",
    "        return all_choices\n",
    "\n",
    "    def detect_multi_choise(column):\n",
    "        return column.str.contains(\";\").sum() > 0\n",
    "\n",
    "    is_multi_choice = data.loc[:, data.dtypes == \"object\"].apply(detect_multi_choise)\n",
    "    multi_choice_columns = is_multi_choice[is_multi_choice].index.to_list()\n",
    "\n",
    "    distinct_choice_lists_for_each_columns = {column: get_all_distinct_choices(column) for column in multi_choice_columns}\n",
    "\n",
    "    def sep_multi_choice(row):\n",
    "        #if int(row.name) % 5 ==0:\n",
    "        #print(round((int(row.name) / len(data)),2))\n",
    "\n",
    "        for column in multi_choice_columns:\n",
    "            for choise in distinct_choice_lists_for_each_columns[column]:\n",
    "                if type(row[column]) is str:\n",
    "                    if  choise in row[column]:\n",
    "                        row[column + \"_\" + choise] = 1\n",
    "                    else:\n",
    "                        row[column + \"_\" + choise] = 0\n",
    " \n",
    "        return row\n",
    "    print(\"Multi choice columns processing is started.\")\n",
    "    ddata = dd.from_pandas(data, npartitions=32)\n",
    "    data = ddata.map_partitions(lambda df: data.apply(sep_multi_choice, axis=1)).compute(get=get) \n",
    "    #data = data.apply(sep_multi_choice, axis=1)\n",
    "    data = data.drop(multi_choice_columns, axis=1)\n",
    "\n",
    "    print(\"Multi choice columns processed.\")\n",
    "\n",
    "    # One hot encoding\n",
    "    cat_columns = [\"Country\", \"Gender\", \"JobSat\", \"JobSeek\",\n",
    "                                        \"Employment\",\n",
    "                                        \"MainBranch\", \n",
    "                                        \"Hobbyist\", \n",
    "                                        \"EdLevel\", \n",
    "                                        \"NEWDevOps\", \n",
    "                                        \"NEWDevOpsImpt\", \n",
    "                                        \"NEWEdImpt\", \n",
    "                                        \"NEWLearn\",\n",
    "                                        \"NEWOffTopic\",\n",
    "                                        \"NEWOnboardGood\",\n",
    "                                        \"NEWOtherComms\",\n",
    "                                        \"NEWOvertime\",\n",
    "                                        \"NEWPurpleLink\",\"OpSys\",\"OrgSize\",\n",
    "                                        \"PurchaseWhat\",\"SOAccount\",\n",
    "                                        \"SOComm\",\"SOPartFreq\",\"SOVisitFreq\",\n",
    "                                        \"SurveyEase\", \"SurveyLength\",\"Trans\", \"UndergradMajor\",\"WelcomeChange\"]\n",
    "    cat_columns = [col for col in cat_columns if col not in multi_choice_columns]\n",
    "    data = pd.get_dummies(data=data, columns=cat_columns)\n",
    "\n",
    "    \n",
    "    data = data.dropna(subset=[\"ConvertedComp\"], axis=0)\n",
    "    # Fill NaNs with mean\n",
    "    nas = data.isna().sum()\n",
    "    nas = nas[nas > 0]\n",
    "\n",
    "    for na_col in nas.index:\n",
    "        data[na_col].fillna(data[na_col].mean(), inplace=True)\n",
    "\n",
    "    #LABEL :\"ConvertedComp\"\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv(\"data_prepared.csv\")\n",
    "except:\n",
    "    data = initial_data_preparation()\n",
    "    data.to_csv(\"data_prepared.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data=data, exclude_columns=None, features_to_use=None, apply_x_col=None, columns_to_bin=None):\n",
    "\n",
    "    \n",
    "    if exclude_columns is not None and features_to_use is not None:\n",
    "        raise Exception(\"exclude_columns and features_to_use cannot be used at the same time.\")\n",
    "\n",
    "    if exclude_columns is not None:\n",
    "        data = data.drop(exclude_columns, axis=1)\n",
    "\n",
    "    if features_to_use is not None:\n",
    "        data = data[features_to_use + [\"revenue\"]]\n",
    "\n",
    "    x = data.drop('ConvertedComp', axis=1)\n",
    "    \n",
    "    y = data['ConvertedComp']\n",
    "\n",
    "    if apply_x_col is not None:\n",
    "        x = x.apply(apply_x_col)\n",
    "    \n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size = 0.25, random_state = 42)\n",
    "\n",
    "    if columns_to_bin is not None:\n",
    "        for column in columns_to_bin:\n",
    "            if column not in x_train.columns: continue\n",
    "            x_train.loc[:,column], bins_ = pd.qcut(x_train.loc[:,column], q=4,  retbins=True, duplicates=\"drop\")\n",
    "            x_test.loc[:,column] = pd.cut(x_test.loc[:,column], bins=bins_, )\n",
    "            \n",
    "            x_train = pd.get_dummies(x_train)\n",
    "            x_test = pd.get_dummies(x_test)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(x_train, x_test, scaler=StandardScaler):\n",
    "\n",
    "    scaler = scaler()\n",
    "    scaler.fit(x_train)\n",
    "\n",
    "    x_train_scaled = scaler.transform(x_train)\n",
    "    x_train_scaled = pd.DataFrame(x_train_scaled, index=x_train.index, columns=x_train.columns)\n",
    "\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "    x_test_scaled = pd.DataFrame(x_test_scaled, index=x_test.index, columns=x_test.columns)\n",
    "\n",
    "    x_train_scaled.fillna(x_train_scaled.mean(), inplace=True)\n",
    "    x_test_scaled.fillna(x_test_scaled.mean(), inplace=True)\n",
    "\n",
    "    return x_train_scaled, x_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_regression(y_true_train, y_pred_train, y_true_test, y_pred_test, model_name=\"\", model=None, num_feat=\"\"):   \n",
    "    return pd.DataFrame.from_records([[\n",
    "                                       metrics.mean_squared_error(y_true_train, y_pred_train),\n",
    "                                       metrics.mean_absolute_error(y_true_train, y_pred_train),\n",
    "                                       metrics.max_error(y_true_train, y_pred_train),\n",
    "                                       metrics.r2_score(y_true_train, y_pred_train), \n",
    "                                      metrics.mean_squared_error(y_true_test, y_pred_test),\n",
    "                                       metrics.mean_absolute_error(y_true_test, y_pred_test),\n",
    "                                       metrics.max_error(y_true_test, y_pred_test),\n",
    "                                       metrics.r2_score(y_true_test, y_pred_test),\n",
    "                                       model,\n",
    "                                       num_feat]],\n",
    "                                     \n",
    "                                     index=[model_name], \n",
    "                                     columns=['mean_squared_error_train', 'mean_absolute_error_train', 'max_error_train', \"r2_score_train\",\n",
    "                                              'mean_squared_error_test', 'mean_absolute_error_test', 'max_error_test', \"r2_score_test\", \"model_object\", \"num_feat\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(x_train, x_test, y_train, y_test, feture_elimination_num_feat=None):\n",
    "        results = pd.DataFrame()\n",
    "        for model in [linear_model.LinearRegression(), \n",
    "                        linear_model.RidgeCV(),\n",
    "                        linear_model.LassoCV(),\n",
    "                        svm.LinearSVR(),\n",
    "                        #svm.SVR(kernel=\"rbf\",),\n",
    "                        #svm.SVR(kernel=\"poly\"),\n",
    "                        tree.DecisionTreeRegressor(),\n",
    "                        RandomForestRegressor()]:\n",
    "                \n",
    "                if feture_elimination_num_feat is not None :\n",
    "                        try:\n",
    "                                if feture_elimination_num_feat == \"auto\":\n",
    "                                        feture_elimination_num_feat = np.linspace(5,len(x_train.columns),5, dtype=int)\n",
    "\n",
    "                                for n_features_to_select in feture_elimination_num_feat:\n",
    "                                        model_ = RFE(estimator=model, n_features_to_select=n_features_to_select)\n",
    "                                        model_.fit(x_train, y_train)\n",
    "                                        y_train_pred = model_.predict(x_train)\n",
    "                                        y_test_pred = model_.predict(x_test)\n",
    "\n",
    "                                        results = results.append(evaluate_regression(y_train, y_train_pred, y_test, y_test_pred,\n",
    "                                                                model_name=type(model_).__name__, model=model_, num_feat=n_features_to_select))\n",
    "                                return results\n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "                                \n",
    "                        \n",
    "               \n",
    "                model.fit(x_train, y_train)\n",
    "                \n",
    "                y_train_pred = model.predict(x_train)\n",
    "                y_test_pred = model.predict(x_test)\n",
    "\n",
    "                results = results.append(evaluate_regression(y_train, y_train_pred, y_test, y_test_pred,\n",
    "                                        model_name=type(model).__name__, model=model, num_feat=len(x_train.columns) ))\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_list = pd.DataFrame()\n",
    "\n",
    "def run(exclude_columns=None, features_to_use=None, name=\"\", apply_x_col=None, x_train_=None, y_train_=None, columns_to_bin=None, feture_elimination_num_feat=None):\n",
    "    global experiment_list\n",
    "    print(name)\n",
    "\n",
    "    x_train, x_test, y_train, y_test, data = prepare_data(exclude_columns=exclude_columns, \n",
    "                                                        features_to_use=features_to_use, \n",
    "                                                        apply_x_col=apply_x_col,\n",
    "                                                        columns_to_bin=columns_to_bin)\n",
    "\n",
    "    if x_train_ is not None or y_train_ is not None:\n",
    "        x_train, y_train = x_train_, y_train_\n",
    "\n",
    "    x_train, x_test = scale_data(x_train, x_test, scaler=StandardScaler)\n",
    "\n",
    "    results = run_models(x_train, x_test, y_train, y_test, feture_elimination_num_feat=feture_elimination_num_feat)\n",
    "\n",
    "    print(\"Min mean_squared_error_test Test\",results.sort_values(\"mean_squared_error_test\").iloc[0][\"mean_squared_error_test\"])\n",
    "\n",
    "    best_model = results.sort_values(\"mean_squared_error_test\").reset_index().loc[[0], [\"mean_squared_error_train\", \n",
    "                                                                                        \"mean_squared_error_test\", \n",
    "                                                                                        \"index\",\n",
    "                                                                                        \"num_feat\",\n",
    "                                                                                        \"model_object\"]].rename({0:name, \"index\":\"model_name\"})\n",
    "    if experiment_list is not None:\n",
    "        experiment_list = experiment_list.append(best_model)\n",
    "\n",
    "    return results.sort_values(\"mean_squared_error_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run(exclude_columns=None, name=\"Initial Run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, data = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}