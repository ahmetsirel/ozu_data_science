{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations:  200\n",
      "Number of columns:  13\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math \n",
    "import statsmodels.api as sm\n",
    "\n",
    "np.random.seed(12)\n",
    "\n",
    "data = pd.read_csv('hsbdemo.csv')\n",
    "    \n",
    "print (\"Number of observations: \", len(data.index))\n",
    "print (\"Number of columns: \", len(data.columns))\n",
    "    \n",
    "data= data.drop('id', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers:  ['write' 'ses_high' 'ses_middle' 'const']\n"
     ]
    }
   ],
   "source": [
    "labels = np.array(data['prog'])\n",
    "features= data.drop('prog', axis = 1)\n",
    "\n",
    "features= features.drop('female', axis = 1)\n",
    "features= features.drop('schtyp', axis = 1)\n",
    "features= features.drop('read', axis = 1)\n",
    "features= features.drop('math', axis = 1)\n",
    "features= features.drop('science', axis = 1)\n",
    "features= features.drop('socst', axis = 1)\n",
    "features= features.drop('honors', axis = 1)\n",
    "features= features.drop('awards', axis = 1)\n",
    "features= features.drop('cid', axis = 1)\n",
    "\n",
    "\n",
    "features = pd.get_dummies(features)\n",
    "\n",
    "features= features.drop('ses_low', axis = 1)\n",
    "features['const'] = 1\n",
    "\n",
    "print (\"Headers: \", features.columns.values)\n",
    "\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.899909\n",
      "         Iterations 6\n",
      "[[-0.05792841 -0.11360264]\n",
      " [-1.162832   -0.98267033]\n",
      " [-0.53329101  0.29139312]\n",
      " [ 2.85218624  5.21820016]]\n"
     ]
    }
   ],
   "source": [
    "mlogit = sm.MNLogit(labels, features)\n",
    "fmlogit = mlogit.fit()\n",
    "fmlogit_margeff = fmlogit.get_margeff()\n",
    "print(fmlogit.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[-0.05792841 -0.11360264]\n",
    "#  [ 1.68935424  4.23552983]\n",
    "#  [ 2.85218624  5.21820016]\n",
    "#  [ 2.31889522  5.50959327]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9437175060266153\n"
     ]
    }
   ],
   "source": [
    "print(math.exp(fmlogit.params[0][0]))\n",
    "#The relative risk ratio for a one-unit increase in the variable write is .9437 for being in general program vs. academic program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3743102330837416\n"
     ]
    }
   ],
   "source": [
    "#temp = fmlogit.params[1][1] - fmlogit.params[2][1]\n",
    "temp = fmlogit.params[1][1]\n",
    "print(math.exp(temp))\n",
    " \n",
    "\n",
    "#The relative risk ratio switching from ses = 1 to 3 is .3743 for being in vocation program vs. academic program.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.548435896760221\n"
     ]
    }
   ],
   "source": [
    "#temp = (30*fmlogit.params[0][1]+fmlogit.params[3][1]) \n",
    "#temp -= (50*fmlogit.params[0][0]+fmlogit.params[2][0])  \n",
    "temp = (30*fmlogit.params[0][1]+fmlogit.params[2][1]+fmlogit.params[3][1]) \n",
    "temp -= (50*fmlogit.params[0][0]+fmlogit.params[3][0])  \n",
    "\n",
    "print(math.exp(temp))\n",
    "\n",
    "\n",
    "\n",
    "#Calculate the relative probability change in being in vocation program vs. being in general program for a student with social economic status equals to 2 and with a writing score of 30 vs for a student with social economic status equals to 1 with a writing score of 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Logistic regression Train Accuracy:  0.6733333333333333\n",
      "Multinomial Logistic regression Test Accuracy:  0.54\n"
     ]
    }
   ],
   "source": [
    "features= data.drop('prog', axis = 1)\n",
    "\n",
    "features= features.drop('female', axis = 1)\n",
    "#features= features.drop('schtyp', axis = 1)\n",
    "features= features.drop('honors', axis = 1)\n",
    "features= features.drop('awards', axis = 1)\n",
    "features= features.drop('cid', axis = 1)\n",
    "\n",
    "\n",
    "features = pd.get_dummies(features)\n",
    "features = np.array(features)\n",
    "train_x, test_x, train_y, test_y = train_test_split(features, labels, test_size = 0.25, random_state = 42)\n",
    "\n",
    "mul_lr = linear_model.LogisticRegression(multi_class='multinomial', solver='newton-cg').fit(train_x, train_y)\n",
    " \n",
    "#print(mul_lr.coef_)\n",
    "print (\"Multinomial Logistic regression Train Accuracy: \", metrics.accuracy_score(train_y, mul_lr.predict(train_x)))\n",
    "print (\"Multinomial Logistic regression Test Accuracy: \", metrics.accuracy_score(test_y, mul_lr.predict(test_x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
