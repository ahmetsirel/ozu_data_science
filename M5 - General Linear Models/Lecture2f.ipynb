{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import random\n",
    "import math \n",
    "import time\n",
    "import sys \n",
    "\n",
    "data = pd.read_csv(\"Concrete_Data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    CMS   R-squared:                       0.613\n",
      "Model:                            OLS   Adj. R-squared:                  0.609\n",
      "Method:                 Least Squares   F-statistic:                     161.0\n",
      "Date:                Fri, 11 Oct 2019   Prob (F-statistic):          4.37e-162\n",
      "Time:                        11:25:20   Log-Likelihood:                -3090.4\n",
      "No. Observations:                 824   AIC:                             6199.\n",
      "Df Residuals:                     815   BIC:                             6241.\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "const              -34.2735     29.931     -1.145      0.253     -93.025      24.478\n",
      "Cement               0.1242      0.010     13.054      0.000       0.105       0.143\n",
      "Blast                0.1037      0.011      9.229      0.000       0.082       0.126\n",
      "Fly Ash              0.0934      0.014      6.687      0.000       0.066       0.121\n",
      "Water               -0.1343      0.046     -2.947      0.003      -0.224      -0.045\n",
      "Superplasticizer     0.2880      0.102      2.810      0.005       0.087       0.489\n",
      "CA                   0.0207      0.011      1.966      0.050    2.79e-05       0.041\n",
      "FA                   0.0256      0.012      2.131      0.033       0.002       0.049\n",
      "Age                  0.1146      0.006     19.064      0.000       0.103       0.126\n",
      "==============================================================================\n",
      "Omnibus:                        3.757   Durbin-Watson:                   2.033\n",
      "Prob(Omnibus):                  0.153   Jarque-Bera (JB):                3.762\n",
      "Skew:                          -0.165   Prob(JB):                        0.152\n",
      "Kurtosis:                       2.974   Cond. No.                     1.07e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.07e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\okano\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "x = data.iloc[:,0:8]\n",
    "y = data.iloc[:,8:]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 100) \n",
    "\n",
    "\n",
    "X_train = sm.add_constant(x_train) ## let's add an intercept (beta_0) to our model\n",
    "X_test = sm.add_constant(x_test) \n",
    "\n",
    "lm2 = sm.OLS(y_train,X_train).fit()\n",
    "\n",
    "print(lm2.summary())\n",
    "\n",
    "y_pred2 = lm2.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Cement  Blast  Fly Ash  Water  Superplasticizer      CA     FA    Age  \\\n",
      "0   540.0    0.0      0.0  162.0               2.5  1040.0  676.0   28.0   \n",
      "1   540.0    0.0      0.0  162.0               2.5  1055.0  676.0   28.0   \n",
      "2   332.5  142.5      0.0  228.0               0.0   932.0  594.0  270.0   \n",
      "3   332.5  142.5      0.0  228.0               0.0   932.0  594.0  365.0   \n",
      "4   198.6  132.4      0.0  192.0               0.0   978.4  825.5  360.0   \n",
      "\n",
      "   Studentized Residuals  \n",
      "0               1.559672  \n",
      "1              -0.917354  \n",
      "2               1.057443  \n",
      "3               0.637504  \n",
      "4              -1.170290  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\okano\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "#Detecting Outliers:\n",
    "influence = lm2.get_influence()  \n",
    "resid_student = influence.resid_studentized_external\n",
    "\n",
    "resid = pd.concat([x_train,pd.Series(resid_student,name = \"Studentized Residuals\")],axis = 1)\n",
    "print(resid.head())\n",
    "\n",
    "#remove studentized residuals > 3\n",
    "resid.loc[np.absolute(resid[\"Studentized Residuals\"]) > 3,:]\n",
    "\n",
    "#get index values\n",
    "ind = resid.loc[np.absolute(resid[\"Studentized Residuals\"]) > 3,:].index\n",
    "\n",
    "#remove from data\n",
    "y_train.drop(ind,axis = 0,inplace = True)\n",
    "x_train.drop(ind,axis = 0,inplace = True)  #Interept column is not there\n",
    "X_train.drop(ind,axis = 0,inplace = True)  #Intercept column is there\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.47758260195686\n",
      "3.2696650121931814\n",
      "4.129325501299344\n",
      "82.21008475163109\n",
      "5.21853674386234\n",
      "85.86694548901554\n",
      "71.81633694293068\n",
      "1.6861600968467656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print vif values\n",
    "[print(variance_inflation_factor(x_train.values, j)) for j in range(x_train.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration no.\n",
      "1\n",
      "[15.47758260195686, 3.2696650121931814, 4.129325501299344, 82.21008475163109, 5.21853674386234, 85.86694548901554, 71.81633694293068, 1.6861600968467656]\n",
      "Max VIF is for variable no.:\n",
      "5\n",
      "Iteration no.\n",
      "2\n",
      "[14.517486362670928, 3.2477734890453647, 3.968695653417151, 71.53530428408644, 5.1775267752249094, 48.27016091702854, 1.68612563105104]\n",
      "Max VIF is for variable no.:\n",
      "3\n",
      "Iteration no.\n",
      "3\n",
      "[9.385732352700503, 2.0828769946572407, 3.009516852485082, 2.910827525646028, 14.418586504418215, 1.572151969798833]\n",
      "Max VIF is for variable no.:\n",
      "4\n",
      "Iteration no.\n",
      "4\n",
      "[2.6936535297265767, 1.5282892036607625, 1.904439437889966, 2.890705249212633, 1.5380724272424997]\n",
      "Max VIF is for variable no.:\n",
      "3\n",
      "     Cement  Blast  Fly Ash  Superplasticizer  Age\n",
      "337   275.1    0.0    121.4               9.9   56\n",
      "384   516.0    0.0      0.0               8.2   28\n",
      "805   393.0    0.0      0.0               0.0   90\n",
      "682   183.9  122.6      0.0               0.0   28\n",
      "329   246.8    0.0    125.1              12.0    3\n"
     ]
    }
   ],
   "source": [
    "def calculate_vif(x):\n",
    "    thresh = 5.0\n",
    "    output = pd.DataFrame()\n",
    "    k = x.shape[1]\n",
    "    vif = [variance_inflation_factor(x.values, j) for j in range(x.shape[1])]\n",
    "    for i in range(1,k):\n",
    "        print(\"Iteration no.\")\n",
    "        print(i)\n",
    "        print(vif)\n",
    "        a = np.argmax(vif)\n",
    "        print(\"Max VIF is for variable no.:\")\n",
    "        print(a)\n",
    "        if vif[a] <= thresh :\n",
    "            break\n",
    "        if i == 1 :          \n",
    "            output = x.drop(x.columns[a], axis = 1)\n",
    "            vif = [variance_inflation_factor(output.values, j) for j in range(output.shape[1])]\n",
    "        elif i > 1 :\n",
    "            output = output.drop(output.columns[a],axis = 1)\n",
    "            vif = [variance_inflation_factor(output.values, j) for j in range(output.shape[1])]\n",
    "    return(output)\n",
    "\n",
    "\n",
    "\n",
    "train_out = calculate_vif(x_train) \n",
    "\n",
    "print(train_out.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    CMS   R-squared:                       0.570\n",
      "Model:                            OLS   Adj. R-squared:                  0.567\n",
      "Method:                 Least Squares   F-statistic:                     216.3\n",
      "Date:                Fri, 11 Oct 2019   Prob (F-statistic):          6.88e-147\n",
      "Time:                        11:30:45   Log-Likelihood:                -3128.8\n",
      "No. Observations:                 823   AIC:                             6270.\n",
      "Df Residuals:                     817   BIC:                             6298.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "const              -11.1119      1.915     -5.803      0.000     -14.871      -7.353\n",
      "Cement               0.1031      0.005     20.941      0.000       0.093       0.113\n",
      "Blast                0.0721      0.006     12.622      0.000       0.061       0.083\n",
      "Fly Ash              0.0614      0.009      6.749      0.000       0.044       0.079\n",
      "Superplasticizer     0.7519      0.077      9.739      0.000       0.600       0.903\n",
      "Age                  0.1021      0.006     16.582      0.000       0.090       0.114\n",
      "==============================================================================\n",
      "Omnibus:                        0.870   Durbin-Watson:                   2.090\n",
      "Prob(Omnibus):                  0.647   Jarque-Bera (JB):                0.945\n",
      "Skew:                           0.039   Prob(JB):                        0.623\n",
      "Kurtosis:                       2.853   Cond. No.                     1.59e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.59e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "2.6936535297265767\n",
      "1.5282892036607625\n",
      "1.904439437889966\n",
      "2.890705249212633\n",
      "1.5380724272424997\n"
     ]
    }
   ],
   "source": [
    "x_test.drop([\"Water\",\"CA\",\"FA\"],axis = 1,inplace = True)\n",
    "\n",
    "Train_out = sm.add_constant(train_out) ## let's add an intercept (beta_0) to our model\n",
    "X_test = sm.add_constant(x_test)\n",
    "lm2 = sm.OLS(y_train,Train_out).fit()\n",
    "print(lm2.summary())\n",
    "\n",
    "[print(variance_inflation_factor(train_out.values, j)) for j in range(train_out.shape[1])]\n",
    "\n",
    "y_pred3 = lm2.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.262654160599253\n",
      "113.17875937789917\n",
      "10.638550623928955\n",
      "8.62405760881035\n",
      "124.42658466679039\n",
      "11.15466649733601\n"
     ]
    }
   ],
   "source": [
    "print(metrics.mean_absolute_error(y_test, y_pred2))\n",
    "print(metrics.mean_squared_error(y_test, y_pred2))\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred2)))\n",
    "\n",
    "print(metrics.mean_absolute_error(y_test, y_pred3))\n",
    "print(metrics.mean_squared_error(y_test, y_pred3))\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    CMS   R-squared:                       0.557\n",
      "Model:                            OLS   Adj. R-squared:                  0.554\n",
      "Method:                 Least Squares   F-statistic:                     171.2\n",
      "Date:                Fri, 11 Oct 2019   Prob (F-statistic):          9.34e-141\n",
      "Time:                        11:33:09   Log-Likelihood:                -3145.6\n",
      "No. Observations:                 824   AIC:                             6305.\n",
      "Df Residuals:                     817   BIC:                             6338.\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         35.9527      0.385     93.367      0.000      35.197      36.709\n",
      "x1            -0.4291      0.254     -1.686      0.092      -0.929       0.070\n",
      "x2             1.0574      0.324      3.265      0.001       0.422       1.693\n",
      "x3             7.9425      0.335     23.694      0.000       7.285       8.600\n",
      "x4            -0.1846      0.384     -0.481      0.631      -0.938       0.569\n",
      "x5             5.6586      0.397     14.256      0.000       4.879       6.438\n",
      "x6             6.7147      0.426     15.777      0.000       5.879       7.550\n",
      "==============================================================================\n",
      "Omnibus:                        0.630   Durbin-Watson:                   2.059\n",
      "Prob(Omnibus):                  0.730   Jarque-Bera (JB):                0.720\n",
      "Skew:                          -0.032   Prob(JB):                        0.698\n",
      "Kurtosis:                       2.870   Cond. No.                         1.67\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "8.839292779934901\n",
      "123.15500428432182\n",
      "11.09752243900961\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 100) \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit on training set only.\n",
    "scaler.fit(x_train)\n",
    "# Apply transform to both the training set and the test set.\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "# Make an instance of the Model\n",
    "pca = PCA(.95)\n",
    "\n",
    "pca.fit(x_train)\n",
    "\n",
    "x_train = pca.transform(x_train)\n",
    "x_test = pca.transform(x_test)\n",
    "\n",
    "X_train = sm.add_constant(x_train) ## let's add an intercept (beta_0) to our model\n",
    "X_test = sm.add_constant(x_test) \n",
    "\n",
    "lm4 = sm.OLS(y_train,X_train).fit()\n",
    "\n",
    "print(lm4.summary())\n",
    "\n",
    "y_pred4 = lm4.predict(X_test) \n",
    "\n",
    "print(metrics.mean_absolute_error(y_test, y_pred4))\n",
    "print(metrics.mean_squared_error(y_test, y_pred4))\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
