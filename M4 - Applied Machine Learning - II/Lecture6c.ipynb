{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math \n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.datasets import boston_housing\n",
    "from numpy.random import seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "\n",
    "seed(1907)\n",
    "tensorflow.random.set_seed(2)\n",
    "\n",
    "\n",
    "from skmultilearn.dataset import load_dataset_dump\n",
    "#from skmultilearn.problem_transformation import BinaryRelevance\n",
    "#from skmultilearn.datasets import load_dataset\n",
    "\n",
    "\n",
    "#X, y = load_dataset('yeast')\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "#X, y, feature_names, label_names = load_dataset_dump('yeast')\n",
    "\n",
    "X, Y = fetch_openml('yeast', version=4, return_X_y=True)\n",
    "Y = Y == 'TRUE'\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2, random_state=0)\n",
    "\n",
    "# this will generate a random multi-label dataset\n",
    "#X, y = make_multilabel_classification(sparse = True, n_labels = 20, return_indicator = 'sparse', allow_unlabeled = False)\n",
    "\n",
    "#sparse: If True, returns a sparse matrix, where sparse matrix means a matrix having a large number of zero elements.\n",
    "#n_labels:  The average number of labels for each instance.\n",
    "#return_indicator: If ‘sparse’ return Y in the sparse binary indicator format.\n",
    "#allow_unlabeled: If True, some instances might not belong to any class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using binary relevance\n",
    "# initialize binary relevance multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "classifier = BinaryRelevance(GaussianNB())\n",
    "\n",
    "# train\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "print(\"hamming loss: \")\n",
    "print(hamming_loss(y_test, predictions))\n",
    "\n",
    "print(\"accuracy:\")\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using classifier chains\n",
    "# initialize classifier chains multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "classifier = ClassifierChain(GaussianNB())\n",
    "\n",
    "# train\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "print(\"hamming loss: \")\n",
    "print(hamming_loss(y_test, predictions))\n",
    "\n",
    "print(\"accuracy:\")\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Label Powerset\n",
    "# initialize Label Powerset multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "classifier = LabelPowerset(GaussianNB())\n",
    "\n",
    "# train\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "print(\"hamming loss: \")\n",
    "print(hamming_loss(y_test, predictions))\n",
    "\n",
    "print(\"accuracy:\")\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MLkNN(k=20)\n",
    "\n",
    "# train\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "print(\"hamming loss: \")\n",
    "print(hamming_loss(y_test, predictions))\n",
    "\n",
    "print(\"accuracy:\")\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = BinaryRelevance(LogisticRegression())\n",
    "classifier.fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"hamming loss: \")\n",
    "print(hamming_loss(y_test, predictions))\n",
    "\n",
    "print(\"accuracy:\")\n",
    "print(accuracy_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Label Powerset\n",
    "# initialize Label Powerset multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "classifier = LabelPowerset(LogisticRegression())\n",
    "\n",
    "# train\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "print(\"hamming loss: \")\n",
    "print(hamming_loss(y_test, predictions))\n",
    "\n",
    "print(\"accuracy:\")\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(100, input_shape=(X_train.shape[1],), kernel_initializer='he_uniform', activation='relu'))\n",
    "model.add(layers.Dense(50, activation='relu'))\n",
    "model.add(layers.Dense(14, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "preds[preds>=0.5] = 1\n",
    "preds[preds<0.5] = 0\n",
    "# score = compare preds and y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hamming loss: \")\n",
    "print(hamming_loss(y_test, preds))\n",
    "\n",
    "print(\"accuracy:\")\n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(100, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(50, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(14, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "preds[preds>=0.5] = 1\n",
    "preds[preds<0.5] = 0\n",
    "# score = compare preds and y_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"hamming loss: \")\n",
    "print(hamming_loss(y_test, preds))\n",
    "\n",
    "print(\"accuracy:\")\n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# created scaler\n",
    "scaler = StandardScaler()\n",
    "# fit scaler on training dataset\n",
    "scaler.fit(X_train)\n",
    "# transform training dataset\n",
    "X_train = scaler.transform(X_train)\n",
    "# transform test dataset\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(200, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(14, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "preds[preds>=0.5] = 1\n",
    "preds[preds<0.5] = 0\n",
    "# score = compare preds and y_test\n",
    "\n",
    "print(\"hamming loss: \")\n",
    "print(hamming_loss(y_test, preds))\n",
    "\n",
    "print(\"accuracy:\")\n",
    "print(accuracy_score(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(100, activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Dense(50, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Dense(14, activation='sigmoid'))\n",
    "\n",
    "opt = optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "model.compile(optimizer=opt,\n",
    "loss='binary_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "preds[preds>=0.5] = 1\n",
    "preds[preds<0.5] = 0\n",
    "# score = compare preds and y_test\n",
    "\n",
    "print(\"hamming loss: \")\n",
    "print(hamming_loss(y_test, preds))\n",
    "\n",
    "print(\"accuracy:\")\n",
    "print(accuracy_score(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
