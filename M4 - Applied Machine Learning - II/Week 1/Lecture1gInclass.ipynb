{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(1907)\n",
    "\n",
    "df = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "\n",
    "print(\"The data size:\", df.shape)\n",
    "\n",
    "## Convert TotalCharges to numeric\n",
    "df['TotalCharges']=pd.to_numeric(df['TotalCharges'],errors='coerce')\n",
    "\n",
    "## Replace yes and No in the Churn column to 1 and 0. 1 for the event and 0 for the censured data.\n",
    "df['Churn']=df['Churn'].apply(lambda x: 1 if x == 'Yes' else 0 )\n",
    "\n",
    "## Impute the null value with the median value\n",
    "\n",
    "df.TotalCharges.fillna(value=df['TotalCharges'].median(),inplace=True)\n",
    "\n",
    "df= df.drop('customerID', axis = 1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)\n",
    "print(\"The data size:\", df.shape)\n",
    "\n",
    "labels = np.array(df['Churn'])\n",
    "df= df.drop('Churn', axis = 1)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(df, labels, test_size = 0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100, max_features=7)\n",
    "\n",
    "rfc = rfc.fit(train_x,train_y)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred3 = rfc.predict(test_x)\n",
    "y_pred_prob = rfc.predict_proba(test_x)[:,1]\n",
    "\n",
    "print(confusion_matrix(test_y, y_pred3))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_y, y_pred3))\n",
    "# print (\"AUC Score:\", roc_auc_score(test_y, y_pred3))\n",
    "# print (\"AUC Score prob:\", roc_auc_score(test_y, y_pred_prob))\n",
    "# print (\"Precision:\", precision_score(test_y, y_pred3))\n",
    "# print (\"Recall:\", recall_score(test_y, y_pred3))\n",
    "print (\"F1 Score:\", f1_score(test_y, y_pred3))\n",
    "\n",
    "# feature_importances = pd.DataFrame(rfc.feature_importances_,\n",
    "#                                   index = train_x.columns,\n",
    "#                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "# print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
